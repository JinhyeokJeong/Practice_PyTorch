{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOXh09Br+Zoy09aZHtYrdg5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"6uyT2ECgla5Q","executionInfo":{"status":"ok","timestamp":1721598206368,"user_tz":300,"elapsed":14926,"user":{"displayName":"Jinhyeok Jeong","userId":"10312269153711275915"}}},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras import models\n","from tensorflow.keras import layers\n","\n","import torch\n","from torch import nn\n","\n","import torchvision\n","\n","import numpy as np\n","import matplotlib.pyplot as plt"]},{"cell_type":"markdown","source":["<b>TensorFlow/Keras:</b>\n","``` python\n","tf.keras.layers.GroupNormalization(\n","    groups=32, axis=-1, epsilon=0.001, center=True, scale=True,\n","    beta_initializer='zeros', gamma_initializer='ones',\n","    beta_regularizer=None, gamma_regularizer=None,\n","    beta_constraint=None, gamma_constraint=None, **kwargs)\n","```\n","Group Normalization divides the channels into groups and computes within each group the mean and variance for normalization. Empirically, its accuracy is more stable than batch norm in a wide range of small batch sizes, if learning rate is adjusted linearly with batch sizes.\n","\n","Relation to Layer Normalization: If the number of groups is set to 1, then this operation becomes nearly identical to Layer Normalization (see Layer Normalization docs for details).\n","\n","Relation to Instance Normalization: If the number of groups is set to the input dimension (number of groups is equal to number of channels), then this operation becomes identical to Instance Normalization. You can achieve this via groups=-1.\n","\n","<b>PyTorch:</b>\n","``` python\n","torch.nn.GroupNorm(num_groups, num_channels, eps=1e-05, affine=True, device=None, dtype=None)\n","```\n","Applies Group Normalization over a mini-batch of inputs.\n","This layer implements the operation as described in the paper Group Normalization.\n","\n","$y=\\dfrac{x-E[x]}{\\sqrt(Var[x]+\\epsilon)}\\ast \\gamma + \\beta$\n","\n","The input channels are separated into num_groups groups, each containing num_channels / num_groups channels. num_channels must be divisible by num_groups. The mean and standard-deviation are calculated separately over the each group. $\\gamma$ and $\\beta$ are learnable per-channel affine transform parameter vectors of size num_channels if affine is True. The standard-deviation is calculated via the biased estimator, equivalent to torch.var(input, unbiased=False).\n","\n","This layer uses statistics computed from input data in both training and evaluation modes.\n","\n","</pre>"],"metadata":{"id":"EUlRVrdteQ01"}},{"cell_type":"markdown","source":["# When parameters ($\\beta$ and $\\gamma$) are initialized as 0 and 1, respectively"],"metadata":{"id":"ZQrCnUd1Lfi9"}},{"cell_type":"code","source":["# define random inputs\n","input_torch = torch.randn(1, 6, 2, 2) # batch, channel, h, w\n","input_tf = tf.convert_to_tensor(input_torch.permute((0,2,3,1))) # batch, h, w, channel\n","\n","# define group normalization layer\n","norm_tf = layers.GroupNormalization(groups=3, axis=-1, epsilon=1e-04)\n","norm_torch = nn.GroupNorm(num_groups=3,num_channels=6, eps=1e-04)\n","\n","out1 = norm_tf(input_tf)\n","out2 = norm_torch(input_torch)\n","# out3 = norm_torch2(input_torch)\n","\n","print('tensorflow output: \\n', out1.numpy().reshape(-1))\n","print('pytorch output: \\n', out2.detach().permute((0,2,3,1)).numpy().reshape(-1))\n","# print('pytorch output2: \\n', out3.detach().numpy().reshape((-1)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q7sV3y9dkUTu","executionInfo":{"status":"ok","timestamp":1721600746630,"user_tz":300,"elapsed":155,"user":{"displayName":"Jinhyeok Jeong","userId":"10312269153711275915"}},"outputId":"709b0938-eb30-4fd8-9cc9-c4d25bdefe33"},"execution_count":89,"outputs":[{"output_type":"stream","name":"stdout","text":["tensorflow output: \n"," [ 0.84968716 -0.5196075  -1.7287757  -0.2732721  -2.4594684   0.9767574\n"," -1.4404817  -0.86852103  0.91459125  1.0332913  -0.16894978  0.2635165\n","  1.4574002   0.18470833 -0.3066881   0.32460397  0.754851    0.5058085\n","  1.1588684  -0.8220539   1.2080045  -1.1717552  -0.11549518  0.24297996]\n","pytorch output: \n"," [ 0.84968716 -0.51960754 -1.728776   -0.2732722  -2.4594686   0.97675747\n"," -1.4404817  -0.86852103  0.9145913   1.0332915  -0.16894983  0.2635165\n","  1.4574002   0.18470833 -0.3066882   0.32460397  0.7548511   0.5058085\n","  1.1588684  -0.8220539   1.2080046  -1.1717553  -0.11549523  0.24297994]\n"]}]},{"cell_type":"code","source":["# see the parameters\n","print('tensorflow:')\n","display(norm_tf.weights)\n","\n","print('pytorch:')\n","display(norm_torch.weight, norm_torch.bias)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":162},"id":"tY-SsPWQNQqN","executionInfo":{"status":"ok","timestamp":1721600749632,"user_tz":300,"elapsed":156,"user":{"displayName":"Jinhyeok Jeong","userId":"10312269153711275915"}},"outputId":"e4ce4b47-934c-4f17-c435-3b9998ca620a"},"execution_count":90,"outputs":[{"output_type":"stream","name":"stdout","text":["tensorflow:\n"]},{"output_type":"display_data","data":{"text/plain":["[<tf.Variable 'group_normalization_42/gamma:0' shape=(6,) dtype=float32, numpy=array([1., 1., 1., 1., 1., 1.], dtype=float32)>,\n"," <tf.Variable 'group_normalization_42/beta:0' shape=(6,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0.], dtype=float32)>]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["pytorch:\n"]},{"output_type":"display_data","data":{"text/plain":["Parameter containing:\n","tensor([1., 1., 1., 1., 1., 1.], requires_grad=True)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Parameter containing:\n","tensor([0., 0., 0., 0., 0., 0.], requires_grad=True)"]},"metadata":{}}]},{"cell_type":"markdown","source":["# What if the same random weights are used?\n"],"metadata":{"id":"RAqXptVqNpwF"}},{"cell_type":"code","source":["n_batch = 2\n","n_channel = 6\n","n_group = 3\n","n_size = 3 # height & width of input\n","\n","gamma = torch.randn(n_channel, requires_grad=True)\n","beta = torch.randn(n_channel, requires_grad=True)\n","\n","# define group normalization layer\n","norm_tf = layers.GroupNormalization(groups=n_group, axis=-1, epsilon=1e-04)\n","norm_torch = nn.GroupNorm(num_groups=n_group,num_channels=n_channel, eps=1e-04)\n","\n","# feed the input first (for some reason, norm_tf did not have weights before it receive input)\n","input_torch = torch.randn(n_batch, n_channel, n_size, n_size) # batch, channel, h, w\n","input_tf = tf.convert_to_tensor(input_torch.permute((0,2,3,1))) # batch, h, w, channel\n","\n","out1 = norm_tf(input_tf)\n","out2 = norm_torch(input_torch)\n","\n","# change the weights\n","norm_tf.set_weights([gamma.detach().numpy(), beta.detach().numpy()])\n","\n","norm_torch.weight = torch.nn.Parameter(gamma) # gamma\n","norm_torch.bias = torch.nn.Parameter(beta) # beta\n","\n","# print the changed weights\n","print('tf gamma: \\n',norm_tf.weights[0])\n","print('torch gamma: \\n',norm_torch.weight)\n","print('tf beta: \\n',norm_tf.weights[1])\n","print('torch beta: \\n',norm_torch.bias)\n","\n","# define random inputs again\n","input_torch = torch.randn(n_batch, n_channel, n_size, n_size) # batch, channel, h, w\n","input_tf = tf.convert_to_tensor(input_torch.permute((0,2,3,1))) # batch, h, w, channel\n","\n","out1 = norm_tf(input_tf)\n","out2 = norm_torch(input_torch)\n","\n","print('tensorflow output: \\n', out1.numpy().reshape((-1)))\n","print('pytorch output: \\n', out2.detach().permute((0,2,3,1)).numpy().reshape((-1)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c64f5H9mNqnW","executionInfo":{"status":"ok","timestamp":1721600781806,"user_tz":300,"elapsed":151,"user":{"displayName":"Jinhyeok Jeong","userId":"10312269153711275915"}},"outputId":"3653c8ed-4db9-4d7e-f3ad-8a29d68d90d2"},"execution_count":92,"outputs":[{"output_type":"stream","name":"stdout","text":["tf gamma: \n"," <tf.Variable 'group_normalization_44/gamma:0' shape=(6,) dtype=float32, numpy=\n","array([ 1.1889397 ,  0.43409932, -0.07469586,  0.18262534, -0.74273956,\n","        0.5033717 ], dtype=float32)>\n","torch gamma: \n"," Parameter containing:\n","tensor([ 1.1889,  0.4341, -0.0747,  0.1826, -0.7427,  0.5034],\n","       requires_grad=True)\n","tf beta: \n"," <tf.Variable 'group_normalization_44/beta:0' shape=(6,) dtype=float32, numpy=\n","array([-0.16885795,  1.9923154 ,  0.19933347,  0.66141623, -1.5776755 ,\n","       -0.08880939], dtype=float32)>\n","torch beta: \n"," Parameter containing:\n","tensor([-0.1689,  1.9923,  0.1993,  0.6614, -1.5777, -0.0888],\n","       requires_grad=True)\n","tensorflow output: \n"," [ 1.0477364   2.7123933   0.2418355   0.72782457 -2.1019793   0.73462945\n","  0.467426    2.1588924   0.27451015  0.9668887  -1.4655087   0.23099075\n","  0.46032774  1.4361737   0.09584648  0.65685666 -1.3608897   0.80878407\n","  0.13111523  1.4709439   0.20161298  0.456112   -1.1804442  -0.67813414\n"," -1.2264485   1.7408135   0.29957572  0.9266623  -1.0255642   0.36925405\n","  1.7327214   1.9808459   0.18613946  0.60001856 -1.7452846  -0.30098885\n"," -0.23147094  2.0962145   0.27180636  0.9945071  -1.6910734   0.35739934\n","  0.5207345   0.91881967  0.28076875  0.61081445 -1.8373694  -1.1296818\n"," -0.6076174   2.0231042   0.15164411  0.52585495 -0.38749075 -0.24037008\n"," -1.1378703   1.7787856   0.17496747  0.45882395 -1.7672925  -0.14695947\n"," -1.4608009   2.6786823   0.267122    0.74370617 -1.9224628   0.56619054\n"," -1.2172816   2.576236    0.36728254  0.8341558  -1.420694    0.27235988\n","  1.2228293   1.9579341   0.20061955  0.6707144  -2.016509    1.005645\n","  0.82548255  2.0145926   0.21504821  0.86318666 -0.64454985  0.5401555\n","  0.7324627   1.6785617   0.16572388  0.349676   -0.6731331  -0.15012924\n","  2.0042229   1.4723269   0.27469563  0.7225118  -1.1845896   0.03808808\n"," -0.8925054   2.0909977   0.15311204  0.8207971  -0.54895085 -1.00493\n"," -1.9687958   1.81874     0.07208218  0.7254814  -1.6164904  -0.29018265]\n","pytorch output: \n"," [ 1.0477364   2.7123933   0.2418355   0.72782457 -2.1019793   0.73462945\n","  0.467426    2.1588924   0.27451015  0.9668887  -1.4655088   0.23099075\n","  0.46032777  1.4361737   0.09584648  0.65685666 -1.3608898   0.80878407\n","  0.1311152   1.4709439   0.20161298  0.456112   -1.1804441  -0.67813414\n"," -1.2264488   1.7408135   0.29957572  0.9266623  -1.0255642   0.36925405\n","  1.7327216   1.9808459   0.18613946  0.60001856 -1.7452846  -0.30098882\n"," -0.23147099  2.0962145   0.27180636  0.9945071  -1.6910734   0.35739934\n","  0.5207345   0.9188197   0.28076875  0.61081445 -1.8373694  -1.1296817\n"," -0.6076175   2.0231042   0.15164411  0.52585495 -0.38749075 -0.24037008\n"," -1.1378704   1.7787856   0.17496748  0.45882395 -1.7672925  -0.14695948\n"," -1.460801    2.6786823   0.267122    0.74370617 -1.9224628   0.5661906\n"," -1.2172816   2.576236    0.36728254  0.83415574 -1.420694    0.2723599\n","  1.2228293   1.9579341   0.20061956  0.6707144  -2.0165093   1.0056452\n","  0.8254824   2.0145926   0.21504821  0.8631866  -0.6445497   0.54015553\n","  0.7324626   1.6785616   0.16572388  0.34967604 -0.67313296 -0.15012926\n","  2.0042229   1.4723269   0.27469563  0.7225118  -1.1845895   0.03808808\n"," -0.89250547  2.0909977   0.15311205  0.820797   -0.54895073 -1.00493\n"," -1.9687958   1.81874     0.07208219  0.7254814  -1.6164904  -0.29018268]\n"]}]}]}